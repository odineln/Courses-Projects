{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Practice of Large Scale Machine Learning - TP1 Avazu<center></h1>\n",
    "<h2><center>ATHENS 2018<center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Field-aware Factorization Machines\n",
    "<br>\n",
    "<font color=\"red\">\n",
    "Afficher les noms des colonnes de la matrice Xtrain_ha\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Créer une liste de liste de colonnes. La nème sous-liste comporte les noms des colonnes du nème champ.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = []\n",
    "fields.append( liste_colonnes_du_premier_champ )\n",
    "fields.append( liste_colonnes_du_deuxième_champ )\n",
    "fields.append( etc. )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Avec enumerate, générer un dictionnaire qui à chaque nom de colonne associe son champ.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicFields = { ... : ...  for i,f in enumerate(fields) for name_col in f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour formatter les données au format LibFFM, nous devons nous assurer que deux colonnes différentes possèdent des modalités différentes. Pour cela, nous ajoutons devant chaque modalité une chaîne de caractère caractéristique de la colonne.\n",
    "<center>\n",
    "x --> 'nom de la colonne ' + str(x)\n",
    "</center>\n",
    "<br>\n",
    "<font color=\"red\">Effectuer cette transformation avec la méthode apply</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ffm = pd.DataFrame()\n",
    "Xtest_ffm = pd.DataFrame()\n",
    "for col in Xtrain_ha.columns:\n",
    "    Xtrain_ffm[col] = Xtrain_ha[col].apply( ... )\n",
    "    Xtest_ffm[col] = Xtest_ha[col].apply( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec np.unique, on créée la liste de toutes les modalités apparaissant dans toutes les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvals = []\n",
    "allcols_ffm = [col for f in fields for col in f]  # Toutes les colonnes appartenant à l'un des champ\n",
    "for col in allcols_ffm:\n",
    "    allvals.append(np.unique(Xtrain_ffm[col]))\n",
    "allvals= [val for sublist in allvals for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "En utilisant \"enumerate\", créer un dictionnaire qui à chaque valeur associe son rang dans la liste allvals.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicFeat = {val:i for i,val in ... }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On les dataframe comme suit : \n",
    "dans chaque colonne \"col\", la valeur \"x\" est remplacée par la chaîne de caractère \"f:v:1\", où f est le champ associé à la colonne et v est l'indice de la modalité x.\n",
    "<font color=\"red\">\n",
    "Inspecter le code ci-dessous.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in allcols_ffm:\n",
    "    f = dicFields[col]\n",
    "    Xtrain_ffm[col] = Xtrain_ffm[col].apply(lambda x:\"{}:{}:1\".format(f,dicFeat[x]) if x in dicFeat else \"\")\n",
    "    Xtest_ffm[col] = Xtest_ffm[col].apply(lambda x:\"{}:{}:1\".format(f,dicFeat[x]) if x in dicFeat else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Pour les deux dataframe obtenues, concaténer à gauche la colonne de clics ytrain ou ytest correspondante</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yXtrain_ffm = pd.concat( ... ,axis=1)\n",
    "yXtest_ffm = pd.concat( ... ,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Que produit la commande ci-dessous ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w = yXtrain_ffm.apply(lambda row:' '.join(row.values),axis=1).values\n",
    "test_w = yXtest_ffm.apply(lambda row:' '.join(row.values),axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Ecrire les dataframe ci-dessus dans un fichier texte</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('train.txt','w')\n",
    "for item in train_w:\n",
    "    thefile.write(\"%s\\n\" % item)\n",
    "\n",
    "# Faire de même pour le test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour apprendre le modèle de FFM, on utilise la librairie LibFFM https://www.csie.ntu.edu.tw/~cjlin/libffm/  \n",
    "Dans le répertoire notebooks/ se trouvent deux exécutables : ffm-train et ffm-predict.  \n",
    "Dans jupyter notebook, le point d'exclamation ! permet de lancer une commande bash.  \n",
    "L'usage est le suivant : \n",
    "\n",
    "-   `ffm-train'\n",
    "\n",
    "    usage: ffm-train [options] training_set_file [model_file]\n",
    "\n",
    "    options:  \n",
    "    -l <lambda>: set regularization parameter (default 0.00002)  \n",
    "    -k <factor>: set number of latent factors (default 4)  \n",
    "    -t <iteration>: set number of iterations (default 15)  \n",
    "    -r <eta>: set learning rate (default 0.2)  \n",
    "    -s <nr_threads>: set number of threads (default 1)  \n",
    "    -p <path>: set path to the validation set  \n",
    "    --quiet: quiet model (no output)  \n",
    "    --no-norm: disable instance-wise normalization  \n",
    "    --auto-stop: stop at the iteration that achieves the best validation loss (must be used with -p)  \n",
    "<br>\n",
    "<font color=\"red\">Apprendre le modèle. On pourra :  \n",
    "- utiliser un paramètre de régularisation de 0.00001  \n",
    "- utiliser un learning rate de 0.05  \n",
    "- utiliser de l'ordre de 15 facteurs latents\n",
    "- effectuer de l'ordre de 30 itérations  \n",
    "- avec l'option -p, passer en paramètres de validation le ficher de test  \n",
    "- activer le mode --autostop \n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'usage de ffm-predict est : ffm-predict nom-fichier-test nom-fichier-modèle fichier-dans-lequel-ecrire-la-prediction  \n",
    "<font color=\"red\">Effectuer la prédiction.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Calculer la log_loss et l'aire sous la courbe roc.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Séparer les données de train Xtrain en deux avec train_test_split.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_meth, Xtrain_blend, ytrain_meth, ytrain_blend = train_test_split(Xtrain,ytrain,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">\n",
    "Entrainer une régression logistique sur Xtrain_meth, et évaluer ses scores sur Xtrain_blend (conserver dans un vecteur).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Entrainer un xgboost sur Xtrain_meth, et évaluer ses scores sur Xtrain_blend (conserver dans un vecteur).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Entrainer un random forest sur Xtrain_meth, et évaluer ses scores sur Xtrain_blend (conserver dans un vecteur).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Entrainer un extraTrees sur Xtrain_meth, et évaluer ses scores sur Xtrain_blend (conserver dans un vecteur).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Entrainer un FFM sur Xtrain_meth, et évaluer ses scores sur Xtrain_blend (conserver dans un vecteur).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Concaténer tous les scores obtenus sur Xtrain_blend pour former une même matrice de design Zblend.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Entrainer une régression logistique sur (Zblend,ytrain_blend).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "Evaluer les performances de la méthode sur la base de test.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeu de données complet\n",
    "La base complète contient 40.000.000 d'instances. Elle se situe dans le répertoire avazu-large-data-set.zip.  \n",
    "Afin de vous épargner le temps de prétraitement (labelisation, hashing), les fichiers train_ha.zip et test_ha.zip contiennent les résultats du feature engineering précédent :\n",
    "- fusion des modalités les moins fréquentes (<20) au sein d'un même label\n",
    "- hashing des valeurs obtenues.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ha = pd.read_csv('../data/train_ha.zip')\n",
    "test_ha = pd.read_csv('../data/test_ha.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Inspecter la première ligne de train_ha. Créer le vecteur ytrain correspondant à la colonne des clics, et la dataframe Xtrain_ha correspondant aux features hashées. Faire de même avec test_ha.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Procéder à l'encodage en dummies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Importer SGDClassifier de sklearn.linear_model et effectuer 5 passes sur les données (utiliser les options loss='log' et n_jobs=-1). \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost   \n",
    "<font color=\"red\">Mettre en oeuvre un classifieur xgboost (avec un nombre modéré d'estimateurs pour limiter le temps de calcul)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Pour des raisons de temps d'exécution, nous adoptons ici l'implémentation Distributed Random Forest de H2O https://www.h2o.ai/ plus performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hftrain = h2o.H2OFrame(train_ha)\n",
    "hftest =  h2o.H2OFrame(test_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "rf.train(x=list(range(1,train_ha.shape[1])), y=0, training_frame=hftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = h2o.as_list(rf.predict(hftest))\n",
    "log_loss(ytest,soft),roc_auc_score(ytest,soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score obtenu : logloss ~0.395, AUC ~0.75  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization Machines\n",
    "Afin de vous éviter le formattage des données au format libFFM, celles ci ont été pré-enregistrée dans ../data/testffm-big.txt et ../data/trainffm-big.txt. \n",
    "<br>\n",
    "<font color=\"red\">Utiliser la commande bash \"head -1 nom_fichier\" pour afficher la première ligne des données de train.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Lancer l'apprentissage des ffm avec les paramètres -l 0.00001 -k 15 -r 0.05 et en précisant le nombre d'itérations souhaité (une passe sur les données prend environ 180 secondes sur une m5-12xlarge).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Effectuer la prédiction et l'évaluation des performances (log-loss, AUC).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
