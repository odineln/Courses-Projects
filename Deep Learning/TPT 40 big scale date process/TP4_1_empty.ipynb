{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP4_1_empty.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iafPdtuncbq7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1><center>Practice of Large Scale Machine Learning<center></h1>\n",
        "<h1><center>TP4.1 MNIST classification using a FCN<center></h1>\n",
        "<h2><center>ATHENS 2018<center></h2>\n",
        "Email address for sending back the TPs: attilio.fiandrotti@telecom-paristech.fr"
      ]
    },
    {
      "metadata": {
        "id": "A_48Zhg_vxTs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As a first step, we may want to switch to a GPU-acceperated VM\n",
        "# In the menu: Runtime->Change runtime type->Hardware Accelerator->GPU.\n",
        "#\n",
        "# This will thest if we have a GPU-equipped VM and return some useful system-level information\n",
        "#!nvidia-smi\n",
        "\n",
        "# Which GNU/Linux distribution is installed on our VM ?\n",
        "#!lsb_release -a\n",
        "\n",
        "# Which version of the Linux kernel our VM has ?\n",
        "#!uname -a\n",
        "\n",
        "# How much free memory our VM has ?\n",
        "#!free -h\n",
        "\n",
        "# Which storage facilities our VM has ?\n",
        "#!mount\n",
        "\n",
        "# Which python version our VM has installed ?\n",
        "#!python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4VrCB5La5rD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing and importing Keras"
      ]
    },
    {
      "metadata": {
        "id": "WMFnWz-UvCvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This shell command will install the keras package into our VM (if not already installed)\n",
        "# Mind the \"!\" escape character at the beginning of the line\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OlKZ3Hnas7B4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing the Keras main module: different backends will have different data ordering:\n",
        "# theano backend: NCHW\n",
        "# tensorflow backend: NHWC \n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_QLz9_jbRZq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading and preparing the MNIST dataset\n",
        "Load the MNIST dataset made available by keras.datasets\n",
        "Verify the amount of system memory available before and after loading the dataset."
      ]
    },
    {
      "metadata": {
        "id": "gG83hGyVmijn",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
        "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
        "from keras.datasets import ...\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRPbU_Z4U6Ac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the pyplot package, visualize the fist sample of the trainig set"
      ]
    },
    {
      "metadata": {
        "id": "x5VAu7oW0Zu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let us visualize the first training sample using the Gnuplot library\n",
        "from matplotlib import pyplot as plt\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7YsRekMVDg-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Turn train and test labels to one-hot encoding"
      ]
    },
    {
      "metadata": {
        "id": "lQbkllF8mnaf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0jv29YLtVO3q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reshape train and test images so that they follow the Tensoflow NWHC ordering.\n",
        "Then, normalize the images so that they have zero-mean (approximate solutions are ok)"
      ]
    },
    {
      "metadata": {
        "id": "ptTRSDo5nJyZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshape to proper images with 1 color channel according to backend scheme\n",
        "img_rows, img_cols = 28, 28\n",
        "train_images = train_images.reshape(...)\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "\n",
        "# Now let us normalize the image in the [0-1] range paying attention to use floats rather than uint8\n",
        "train_images = train_images.astype('float32')\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uwm1OFOtc4uU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining the neural network architecture (i.e., the network model)"
      ]
    },
    {
      "metadata": {
        "id": "FRh1r3pyGiQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnKYaP-KVoOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a LeNet300-like FC network taking in input the images as vectors of pixels and suitable to classify each image across 10 different classes."
      ]
    },
    {
      "metadata": {
        "id": "Pnd3q1V3nk8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Sequential module is a container for more complex NN elements and\n",
        "# defines a loop-less NN architecture\n",
        "from keras.models import Sequential, Dense, Activation, Flatten\n",
        "\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "# Let us have a look at the model topology\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7g2PNEiwWBLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Instantiate a SGD optimizer with a tentative LR of 10^-3 and using the appropriate loss function and compile the model"
      ]
    },
    {
      "metadata": {
        "id": "SijGZGKjV9J2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The optimizers module provides a number of optimization algorithms for updating\n",
        "# a netwok parameters accoridng to teh computed error gradints\n",
        "from keras import optimizers\n",
        "\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_AWUAW4idF3D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training the network"
      ]
    },
    {
      "metadata": {
        "id": "u-WqMtSAWTRp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model for 10 epochs and over 10k training samples initially only using the fit() method, validating the model at each epoch and keeping track of the training history"
      ]
    },
    {
      "metadata": {
        "id": "gTHrbb7uFYWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is where the actual training-testing happens\n",
        "# Number of epochs we want to train\n",
        "epochs = 10\n",
        "# We restrict the training to 10k images to start with\n",
        "n_train_samples = 10000\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODUc5Bq_dMEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing the network performance\n",
        "Visualize the training history using the pyplot package: plot in one graph the train and vaidation loss functions, in another graph the train and validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "QdJrRbyariEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We now want to plot the train and validation loss functions and accuracy curves\n",
        "#print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "plt.show()\n",
        "\n",
        "# summarize history for accuracy\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nr4TdWoEoDzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "Note down the performance of the trained network in terms of training and validation accuracy as a reference.\n",
        "Then,  experiment as follow and compare performance with the reference scenario:\n",
        "\n",
        "*  What is teh coputational complexity of the first fully connected layer ?\n",
        "*  How to decide when to stop a training session ?\n",
        "*  Experiment gradually increasing the number of training samples from 10'000 to 50'000 and compare performance with reference. Also, observe how training and validation curves change.\n",
        "*  Experiment gradually increasing the learning rate starting from 10^-4 and find the maximum value the network can tolerate without diverging.\n",
        "*   Experiment replacing the sigmoid activations with Relus and note what happens.\n",
        "*   Experiment changing the batch size (inlcuding purely stochastic case) and compare performance with reference.\n",
        "*   Experiment shuffling the samples at each batch and compare performance with reference.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}